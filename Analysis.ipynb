{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a175ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 09:04:50,477 - INFO - Loading data from RawData.csv\n",
      "2024-08-30 09:04:50,480 - INFO - Data loaded. Shape: (32, 20)\n",
      "2024-08-30 09:04:50,506 - INFO - Clustered data saved to 'main_data.csv'\n",
      "2024-08-30 09:04:50,510 - INFO - t-SNE results saved to 'pros_data.csv'\n",
      "2024-08-30 09:04:52,082 - INFO - Scatter plot saved to clustering_images.png\n",
      "2024-08-30 09:04:52,083 - INFO - Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_and_preprocess_data(file_path: str) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load data from CSV and preprocess it.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, List[str]]: Preprocessed data and list of character names.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading data from {file_path}\")\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract character names and remove from main data\n",
    "    character_names = data.iloc[:, 0].tolist()\n",
    "    main_data = data.iloc[:, 1:]\n",
    "    \n",
    "    logger.info(f\"Data loaded. Shape: {main_data.shape}\")\n",
    "    return main_data, character_names\n",
    "\n",
    "def create_preprocessing_pipeline() -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a preprocessing pipeline for numeric data.\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: Scikit-learn pipeline for data preprocessing.\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the data using separate pipelines for numeric and text data.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Raw input data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed data.\n",
    "    \"\"\"\n",
    "    numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "    text_columns = data.select_dtypes(exclude=[np.number]).columns\n",
    "    \n",
    "    # Preprocess numeric data\n",
    "    numeric_pipeline = create_preprocessing_pipeline()\n",
    "    numeric_data = pd.DataFrame(\n",
    "        numeric_pipeline.fit_transform(data[numeric_columns]),\n",
    "        columns=numeric_columns\n",
    "    )\n",
    "    \n",
    "    # Preprocess text data (if any)\n",
    "    if not text_columns.empty:\n",
    "        logger.info(f\"Text columns found: {text_columns}\")\n",
    "        tfidf = TfidfVectorizer(max_features=100)  # Adjust max_features as needed\n",
    "        text_data = pd.DataFrame(\n",
    "            tfidf.fit_transform(data[text_columns].fillna('').astype(str).agg(' '.join, axis=1)).toarray(),\n",
    "            columns=[f'tfidf_{i}' for i in range(100)]\n",
    "        )\n",
    "        return pd.concat([numeric_data, text_data], axis=1)\n",
    "    \n",
    "    return numeric_data\n",
    "\n",
    "def cluster_data(data: pd.DataFrame, n_clusters: int = 8) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on the data.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Preprocessed data.\n",
    "        n_clusters (int): Number of clusters.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Cluster labels.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    return kmeans.fit_predict(data)\n",
    "\n",
    "def apply_dimensionality_reduction(data: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply t-SNE for dimensionality reduction.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Preprocessed data.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Reduced data (3D).\n",
    "    \"\"\"\n",
    "    tsne = KernelPCA(n_components=3, random_state=42)\n",
    "    return tsne.fit_transform(data)\n",
    "\n",
    "def get_image(path: str, zoom: float = 0.4) -> OffsetImage:\n",
    "    \"\"\"\n",
    "    Load and resize image for plot annotation.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to the image file.\n",
    "        zoom (float): Zoom factor for the image.\n",
    "    \n",
    "    Returns:\n",
    "        OffsetImage: Resized image for plot annotation.\n",
    "    \"\"\"\n",
    "    return OffsetImage(plt.imread(path), zoom=zoom)\n",
    "\n",
    "def create_scatter_plot(tsne_df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"\n",
    "    Create a scatter plot with character images.\n",
    "    \n",
    "    Args:\n",
    "        tsne_df (pd.DataFrame): DataFrame with t-SNE results and character names.\n",
    "        output_path (str): Path to save the output image.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    scatter = plt.scatter(tsne_df['x'], tsne_df['y'], alpha=0)\n",
    "\n",
    "    for i, character in enumerate(tsne_df['Entity']):\n",
    "        try:\n",
    "            img_path = os.path.join('images', f\"{character.lower().replace(' ', '_')}.png\")\n",
    "            ab = AnnotationBbox(get_image(img_path), (tsne_df['x'][i], tsne_df['y'][i]), frameon=False)\n",
    "            plt.gca().add_artist(ab)\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(f\"Image not found for {character}\")\n",
    "\n",
    "    plt.title('Political Compass', fontsize=36)\n",
    "    plt.xlabel('Component 1', fontsize=36)\n",
    "    plt.ylabel('Component 2', fontsize=36)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Scatter plot saved to {output_path}\")\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    main_data, character_names = load_and_preprocess_data('RawData.csv')\n",
    "    processed_data = preprocess_data(main_data)\n",
    "    \n",
    "    # Cluster the processed data\n",
    "    main_clusters = cluster_data(processed_data)\n",
    "    \n",
    "    # Save clustered data\n",
    "    clustered_data = processed_data.copy()\n",
    "    clustered_data['Cluster'] = main_clusters\n",
    "    clustered_data.to_csv('main_data.csv', index=False)\n",
    "    logger.info(\"Clustered data saved to 'main_data.csv'\")\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    tsne_result = apply_dimensionality_reduction(processed_data)\n",
    "    \n",
    "    # Prepare results for visualization\n",
    "    tsne_df = pd.DataFrame(tsne_result, columns=['x', 'y', 'z'])\n",
    "    tsne_df['Entity'] = character_names\n",
    "    tsne_df.to_csv(\"pros_data.csv\", index=False)\n",
    "    logger.info(\"t-SNE results saved to 'pros_data.csv'\")\n",
    "    \n",
    "    # Create and save the scatter plot\n",
    "    create_scatter_plot(tsne_df, 'clustering_images.png')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    logger.info(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
